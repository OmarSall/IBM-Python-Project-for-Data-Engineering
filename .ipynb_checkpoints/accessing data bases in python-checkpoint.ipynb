{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17906bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/INSTRUCTOR.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c407a39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd \n",
    "\n",
    "#connect and create new database\n",
    "conn = sqlite3.connect('STAFF.db')\n",
    "\n",
    "table_name = 'INSTRUCTOR'\n",
    "attribute_list = ['ID', 'FNAME', 'LNAME', 'CITY', 'CCODE']\n",
    "\n",
    "file_path = '/home/project/INSTRUCTOR.csv'\n",
    "#adding headeres due to lack of headers at the beggining\n",
    "df = pd.read_csv(file_path, names = attribute_list)\n",
    "\n",
    "# df.to_sql(table_name, conn, if_exists = 'replace', index=False)\n",
    "# print(\"Table is ready\")\n",
    "\n",
    "\n",
    "\n",
    "query_statement = f\"SELECT * FROM {table_name}\"\n",
    "query_output = pd.read_sql(query_statement, conn)\n",
    "\n",
    "# query_statement = f\"SELECT FNAME FROM {table_name}\"\n",
    "# query_output = pd.read_sql(query_statement, conn)\n",
    "\n",
    "# query_statement = f\"SELECT COUNT(*) FROM {table_name}\"\n",
    "# query_output = pd.read_sql(query_statement, conn)\n",
    "\n",
    "print(query_statement)\n",
    "print(query_output)\n",
    "\n",
    "# data_dict = {'ID' : [100],\n",
    "#             'FNAME' : ['John'],\n",
    "#             'LNAME' : ['Doe'],\n",
    "#             'CITY' : ['Paris'],\n",
    "#             'CCODE' : ['FR']}\n",
    "\n",
    "# data_append=pd.DataFrame(data_dict)\n",
    "\n",
    "# data_append.to_sql(table_name, conn, if_exists = 'append', index =False)\n",
    "# print('Data appended successfully')\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7e134e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c2767e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Height Qualification  Age\n",
      "0     Jai     5.1           Msc   21\n",
      "1  Princi     6.2            MA   23\n",
      "2  Gaurav     5.1           Msc   24\n",
      "3    Anuj     5.2           Msc   21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    " \n",
    "# Define a dictionary containing Students data\n",
    "data = {'Name': ['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
    "        'Height': [5.1, 6.2, 5.1, 5.2],\n",
    "        'Qualification': ['Msc', 'MA', 'Msc', 'Msc']}\n",
    " \n",
    "# Convert the dictionary into DataFrame\n",
    "df = pd.DataFrame(data)\n",
    " \n",
    "# Using DataFrame.insert() to add a column\n",
    "df.insert(3, \"Age\", [21, 23, 24, 21], True)\n",
    " \n",
    "# Observe the result\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ef6659",
   "metadata": {},
   "source": [
    "# FINAL EXAM OF THE COURSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c169398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET \n",
    "from datetime import datetime\n",
    "import glob\n",
    "import numpy as np \n",
    "\n",
    "log_file = \"./code_log.txt\"\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_largest_banks'\n",
    "table_attribs = [\"Name\", \"MC_USD_Billion\"]\n",
    "db_name = 'Banks.db'\n",
    "table_name = 'Largest_banks'\n",
    "csv_path = './Largest_banks.csv'\n",
    "\n",
    "\n",
    "def log_progress(message):\n",
    "    \n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second \n",
    "    now = datetime.now() # get current timestamp \n",
    "    timestamp = now.strftime(timestamp_format) \n",
    "    with open(log_file,\"a\") as f: \n",
    "        f.write(timestamp + ',' + message + '\\n') \n",
    "\n",
    "def extract(url, table_attribs): \n",
    "    \n",
    "    html_page = requests.get(url).text\n",
    "    data = BeautifulSoup(html_page, 'html.parser')\n",
    "\n",
    "    df = pd.DataFrame(columns=table_attribs) # create an empty data frame to hold extracted data \n",
    "    \n",
    "    tables = data.find_all('tbody')\n",
    "    rows = tables[0].find_all('tr')\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for row in rows:\n",
    "        if count < 11:\n",
    "            col = row.find_all('td')\n",
    "            if len(col) != 0:\n",
    "                \n",
    "                data_dict = {\"Name\": col[1].contents[2],\n",
    "                            \"MC_USD_Billion\": float(col[2].contents[0])}\n",
    "                df1 = pd.DataFrame(data_dict, index=[0])\n",
    "                df = pd.concat([df,df1], ignore_index=True)\n",
    "                count+=1\n",
    "        else:\n",
    "            break\n",
    "    return df\n",
    "\n",
    "\n",
    "def transform(df):\n",
    "    currency_list = df['MC_USD_Billion']\n",
    "    MC_GBP_Billion = np.round([0.93 * x for x in currency_list],2)\n",
    "    MC_EUR_Billion = np.round([0.8 * x for x in currency_list],2)\n",
    "    MC_INR_Billion = np.round([82.95 * x for x in currency_list],2)\n",
    "\n",
    "    df['MC_GBP_Billion'] = MC_GBP_Billion\n",
    "    df['MC_EUR_Billion'] = MC_EUR_Billion\n",
    "    df['MC_INR_Billion'] = MC_INR_Billion\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_to_csv(df, csv_path):\n",
    "    df.to_csv(csv_path)\n",
    "\n",
    "\n",
    "def load_to_db(df, sql_connection, table_name):\n",
    "    df.to_sql(table_name, sql_connection, if_exists='replace',  index=False)\n",
    "\n",
    "def run_query(query_statement, sql_connection):\n",
    "    print(query_statement)\n",
    "    query_output = pd.read_sql(query_statement, sql_connection)\n",
    "    print(query_output)\n",
    "\n",
    "\n",
    "log_progress('Preliminaries complete. Initiating ETL process')\n",
    "\n",
    "df = extract(url, table_attribs)\n",
    "\n",
    "log_progress('Data extraction complete. Initiating transformation process')\n",
    "\n",
    "df = transform(df)\n",
    "\n",
    "log_progress('Data transformation complete. Initiating loading process')\n",
    "\n",
    "load_to_csv(df, csv_path)\n",
    "\n",
    "log_progress('Data saved to CSV file')\n",
    "\n",
    "sql_connection = sqlite3.connect(db_name)\n",
    "\n",
    "log_progress('SQL Connection initiated')\n",
    "\n",
    "load_to_db(df, sql_connection,table_name)\n",
    "\n",
    "log_progress('Data loaded to Database as table. Running the query')\n",
    "\n",
    "query_statement = f\"SELECT * from {table_name}\"\n",
    "\n",
    "run_query(query_statement, sql_connection)\n",
    "\n",
    "log_progress(\"Process complete.\")\n",
    "\n",
    "sql_connection.close()\n",
    "\n",
    "log_progress(\"Server Connection closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
