{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48e6765a",
   "metadata": {},
   "source": [
    "# ETL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78f0058",
   "metadata": {},
   "source": [
    "## Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ff429c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_from_csv(file_to_process):\n",
    "    dataframe = pd.read_csv(file_to_process, lines=True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3db0b4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_json(file_to_process):\n",
    "    dataframe = pd.read_json(file_to_process, lines=True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1975807e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = extract_from_csv('source1.csv')  #file format can be either json or csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6cf4cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    #create an empty data frame to hold extracted data\n",
    "    extracted_data = pd.DataFrame(coluumns=['name','height','weight'])\n",
    "    \n",
    "    #process all csv files\n",
    "    for csvfile in glob.glob(\"*.csv\"):\n",
    "        extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n",
    "        \n",
    "    #process all json files\n",
    "    for jsonfile in glob.glob(\"*.json\"):\n",
    "        extracted_data = extracted_data.append(extract_from_json(jsonfile), ignore_index=True)\n",
    "        \n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bceb4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d5fb3fa",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f307c96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data):\n",
    "    #inches -> m and round off to two decimals (1 inch = 0.0254 m)\n",
    "    data['height'] = round(data.height * 0.0254, 2)\n",
    "    \n",
    "    #pounds -> kg (1 pound = 0.45359237 kg)\n",
    "    data['weight'] = round(data.weight * 0.45359237, 2)\n",
    "    \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd09f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55683d4a",
   "metadata": {},
   "source": [
    "## Load and log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265d1b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(targetfile, data_to_load):\n",
    "    data_to_load.to_csv(targetfile)\n",
    "    \n",
    "target_file = \"transformed_data.csv\"\n",
    "\n",
    "load(targetfile, transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f689b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "151bbc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(message):\n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S'\n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open ( \"logfile.txt\" , \"a\") as f:\n",
    "        f.write (timestamp + ',' + message + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e18eed",
   "metadata": {},
   "source": [
    "## ETL LAB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581e9459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w terminalu\n",
    "wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip\n",
    "Copied!Executed!\n",
    "b. Unzip the downloaded file.\n",
    "\n",
    "unzip source.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1761a450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd \n",
    "import xml.etree.ElementTree as ET \n",
    "from datetime import datetime\n",
    "\n",
    "log_file = \"log_file.txt\"\n",
    "target_file = \"transformed_data.csv\"\n",
    "\n",
    "\n",
    "def extract_from_csv(file_to_process):\n",
    "    dataframe = pd.read_csv(file_to_process)\n",
    "    return dataframe\n",
    "\n",
    "def extract_from_json(file_to_process):\n",
    "    dataframe = pd.read_json(file_to_process, lines=True)\n",
    "    return dataframe\n",
    "\n",
    "def extract_from_xml(file_to_process):\n",
    "    dataframe = pd.DataFrame(columns=['name','height', 'weight'])\n",
    "    tree = ET.parse(file_to_process)\n",
    "    root = tree.getroot()\n",
    "    for person in root:\n",
    "        name = person.find(\"name\").text\n",
    "        height = float(person.find(\"height\").text)\n",
    "        weight = float(person.find(\"weight\").text) \n",
    "        dataframe = pd.concat([dataframe, pd.DataFrame([{\"name\":name, \"height\": height, \"weight\":weight}])], ignore_index=True)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def extract(): \n",
    "    extracted_data = pd.DataFrame(columns=['name','height','weight']) # create an empty data frame to hold extracted data \n",
    "     \n",
    "    # process all csv files \n",
    "    for csvfile in glob.glob(\"*.csv\"): \n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_csv(csvfile))], ignore_index=True) \n",
    "         \n",
    "    # process all json files \n",
    "    for jsonfile in glob.glob(\"*.json\"): \n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_json(jsonfile))], ignore_index=True) \n",
    "     \n",
    "    # process all xml files \n",
    "    for xmlfile in glob.glob(\"*.xml\"): \n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_xml(xmlfile))], ignore_index=True) \n",
    "         \n",
    "    return extracted_data \n",
    "\n",
    "def transform(data): \n",
    "    '''Convert inches to meters and round off to two decimals \n",
    "    1 inch is 0.0254 meters '''\n",
    "    data['height'] = round(data.height * 0.0254,2) \n",
    " \n",
    "    '''Convert pounds to kilograms and round off to two decimals \n",
    "    1 pound is 0.45359237 kilograms '''\n",
    "    data['weight'] = round(data.weight * 0.45359237,2) \n",
    "    \n",
    "    return data \n",
    "\n",
    "#to_csv() allows to save a dataframe to csv file\n",
    "def load_data(target_file, transformed_data): \n",
    "        transformed_data.to_csv(target_file) \n",
    "\n",
    "def log_progress(message): \n",
    "        timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second \n",
    "        now = datetime.now() # get current timestamp \n",
    "        timestamp = now.strftime(timestamp_format) \n",
    "        with open(log_file,\"a\") as f: \n",
    "            f.write(timestamp + ',' + message + '\\n') \n",
    "\n",
    "\n",
    "\n",
    "# Log the initialization of the ETL process\n",
    "log_progress(\"ETL Job Started\")\n",
    "\n",
    "# Log the beginning of the Extraction process \n",
    "log_progress(\"Extract phase Started\")\n",
    "extracted_data = extract()\n",
    "\n",
    "# Log the completion of the Extraction process \n",
    "log_progress(\"Extract phase Ended\")\n",
    "\n",
    "#Log the beginning of the Transformation process\n",
    "log_progress(\"Transform phase started\")\n",
    "transformed_data = transform(extracted_data)\n",
    "print(\"Transformed data: \", transformed_data)\n",
    "\n",
    "# Log the completion of the Tranformation process\n",
    "log_progress(\"Transform phase Ended\") \n",
    "\n",
    "# Log the beginning of the Loading process \n",
    "log_progress(\"Load phase Started\") \n",
    "load_data(target_file,transformed_data) \n",
    "\n",
    "\n",
    "# Log the completion of the Loading process \n",
    "log_progress(\"Load phase Ended\") \n",
    " \n",
    "# Log the completion of the ETL process \n",
    "log_progress(\"ETL Job Ended\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27c15ab",
   "metadata": {},
   "source": [
    "# Practice lab excercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cce2617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd \n",
    "import xml.etree.ElementTree as ET \n",
    "from datetime import datetime \n",
    "\n",
    "log_file = \"log_file.txt\"\n",
    "target_file = \"transformed_data.csv\"\n",
    "\n",
    "def extract_from_csv(file_to_process):\n",
    "    dataframe = pd.read_csv(file_to_process)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def extract_from_json(file_to_process):\n",
    "    dataframe = pd.read_json(file_to_process, lines = True)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def extract_from_xml():\n",
    "    dataframe = pd.DataFrame(columns = ['car_mode','year_of_manufacture','price','fuel'])\n",
    "    tree = ET.parse(file_to_process)\n",
    "    root = tree.getroot()\n",
    "    for car in root:\n",
    "        car_mode = car.find('car_mode').text\n",
    "        year_of_manufacture = car.find('year_of_manufacture').text\n",
    "        price = float(car.find('price').text)\n",
    "        fuel = car.find('fuel').text\n",
    "        dataframe = pd.concat([dataframe, pd.DataFrame([{\n",
    "            \"car_mode\":car_mode,\n",
    "            \"year_of_manufacture\":year_of_manufacture,\n",
    "            \"price\":price,\n",
    "            \"fuel\":fuel\n",
    "        }])], ignore_index=True)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def extract():\n",
    "    extracted_data = pd.DataFrame(columns = ['car_model','year_of_manufacture','price','fuel'])\n",
    "\n",
    "    for csvfile in glob.glob(\"*.csv\"):\n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_csv(csvfile))], ignore_index=True)\n",
    "\n",
    "    for jsonfile in glob.glob(\"*.json\"):\n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_json(jsonfile))], ignore_index=True)\n",
    "\n",
    "    for xmlfile  in glob.glob(\".xml\"):\n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_xml(xmlfile)),], ignore_index=True)\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "def transform(data):\n",
    "    data['price'] = round(data.price, 2)\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_data(target_file, transformed_data):\n",
    "    transformed_data.to_csv(target_file)\n",
    "\n",
    "def log_progress(message):\n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S'\n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(timestamp + ' , ' + message + '\\n')\n",
    "\n",
    "# Log the initialization of the ETL process\n",
    "log_progress(\"ETL Job Started\")\n",
    "\n",
    "# Log the beginning of the Extraction process \n",
    "log_progress(\"Extract phase Started\")\n",
    "extracted_data = extract()\n",
    "\n",
    "# Log the completion of the Extraction process \n",
    "log_progress(\"Extract phase Ended\")\n",
    "\n",
    "#Log the beginning of the Transformation process\n",
    "log_progress(\"Transform phase started\")\n",
    "transformed_data = transform(extracted_data)\n",
    "print(\"Transformed data: \", transformed_data)\n",
    "\n",
    "# Log the completion of the Tranformation process\n",
    "log_progress(\"Transform phase Ended\") \n",
    "\n",
    "# Log the beginning of the Loading process \n",
    "log_progress(\"Load phase Started\") \n",
    "load_data(target_file,transformed_data) \n",
    "\n",
    "# Log the completion of the Loading process \n",
    "log_progress(\"Load phase Ended\") \n",
    " \n",
    "# Log the completion of the ETL process \n",
    "log_progress(\"ETL Job Ended\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
