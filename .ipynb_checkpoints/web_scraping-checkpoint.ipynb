{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb1a131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://web.archive.org/web/20230902185655/https://en.everybodywiki.com/100_Most_Highly-Ranked_Films'\n",
    "db_name = 'Movies.db'\n",
    "table_name = 'Top_50'\n",
    "csv_path = '/home/project/top_50_films.csv'\n",
    "df = pd.DataFrame(columns=[\"Average Rank\", \"Film\", \"Year\"])\n",
    "count = 0\n",
    "\n",
    "#loading the entire web page as an html document\n",
    "html_page = requests.get(url).text\n",
    "\n",
    "#parse the text in the HTML format using BeautifulSoup to enable extraction of relevant information\n",
    "data = BeautifulSoup(html_page, 'html.parser')\n",
    "\n",
    "#finding all the tables in the web page\n",
    "tables = data.find_all('tbody')\n",
    "#variable rows gets all the rows in the first table\n",
    "rows = tables[0].find_all('tr')\n",
    "\n",
    "#we need to extract first 50 movies\n",
    "\n",
    "for row in rows:\n",
    "    if count < 50:\n",
    "        col = row.find_all('td')\n",
    "        if len(col) != 0:\n",
    "            data_dict = { \"Average Rank\": col[0].contents[0],\n",
    "                           \"Film\": col[1].contents[0],\n",
    "                           \"Year\": col[2].contents[0]}\n",
    "            df1 = pd.DataFrame(data_dict, index=[0])\n",
    "            df = pd.concat([df,df1], ignore_index=True)\n",
    "            count+=1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.to_csv(csv_path)\n",
    "\n",
    "#initializing the connection to a database\n",
    "conn = sqlite3.connect(db_name)\n",
    "df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8ba167",
   "metadata": {},
   "source": [
    "The if_exists parameter can take any one of three possible values:\n",
    "\n",
    "'fail': This denies the creation of a table if one with the same name exists in the database already.\n",
    "\n",
    "'replace': This overwrites the existing table with the same name.\n",
    "\n",
    "'append': This adds information to the existing table with the same name.\n",
    "\n",
    "Keep the index parameter set to True only if the index of the data being sent holds some informational value. Otherwise, keep it as False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da19ed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_sql(query_statement, sql_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1561be86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d266da3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb08b282",
   "metadata": {},
   "source": [
    "# Project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c713a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for ETL operations on Country-GDP data \n",
    "#Author: Omar Salloum\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET \n",
    "from datetime import datetime\n",
    "import glob\n",
    "import numpy as np \n",
    "\n",
    "log_file = \"./etl_project_log.txt\"\n",
    "target_file = \"transformed_data.csv\"\n",
    "\n",
    "url = 'https://web.archive.org/web/20230902185326/https://en.wikipedia.org/wiki/List_of_countries_by_GDP_%28nominal%29'\n",
    "table_attribs = [\"Country\", \"GDP_USD_millions\"]\n",
    "db_name = 'World_Economies.db'\n",
    "table_name = 'Countries_by_GDP'\n",
    "csv_path = './Countries_by_GDP.csv'\n",
    "\n",
    "# def extract_from_csv(file_to_process):\n",
    "#     dataframe = pd.read_csv(file_to_process)\n",
    "#     return dataframe\n",
    "\n",
    "# def extract_from_json(file_to_process):\n",
    "#     dataframe = pd.read_json(file_to_process, lines=True)\n",
    "#     return dataframe\n",
    "\n",
    "# def extract_from_xml(file_to_process):\n",
    "#     dataframe = pd.DataFrame(columns=table_attribs)\n",
    "#     tree = ET.parse(file_to_process)\n",
    "#     root = tree.getroot()\n",
    "#     for item in root:\n",
    "#         country = item.find(\"Country\").text\n",
    "#         gdp = float(item.find(\"GDP_USD_milions\").text)\n",
    "#         dataframe = pd.concat([dataframe, pd.DataFrame([{\"Country\":country, \"GDP_USD_milions\": gdp}])], ignore_index=True)\n",
    "#     return dataframe\n",
    "\n",
    "\n",
    "def extract(url, table_attribs): \n",
    "    \n",
    "    html_page = requests.get(url).text\n",
    "    data = BeautifulSoup(html_page, 'html.parser')\n",
    "\n",
    "    df = pd.DataFrame(columns=table_attribs) # create an empty data frame to hold extracted data \n",
    "    \n",
    "    tables = data.find_all('tbody')\n",
    "    rows = tables[2].find_all('tr')\n",
    "\n",
    "    for row in rows:\n",
    "        col = row.find_all('td')\n",
    "        if len(col) != 0:\n",
    "            if col[0].find('a') is not None and 'â€”' not in col[2]:\n",
    "                data_dict = {\"Country\": col[0].a.contents[0],\n",
    "                             \"GDP_USD_millions\": col[2].contents[0]}\n",
    "                df1 = pd.DataFrame(data_dict, index=[0])\n",
    "                df = pd.concat([df,df1], ignore_index=True)\n",
    "\n",
    "    return df \n",
    "\n",
    "\n",
    "\n",
    "def transform(df):\n",
    "    ''' This function converts the GDP information from Currency\n",
    "    format to float value, transforms the information of GDP from\n",
    "    USD (Millions) to USD (Billions) rounding to 2 decimal places.\n",
    "    The function returns the transformed dataframe.'''\n",
    "\n",
    "    GDP_list = df[\"GDP_USD_millions\"].tolist()\n",
    "    GDP_list = [float(\"\".join(x.split(','))) for x in GDP_list]\n",
    "    GDP_list = [np.round(x/1000,2) for x in GDP_list]\n",
    "    df[\"GDP_USD_millions\"] = GDP_list\n",
    "    df=df.rename(columns = {\"GDP_USD_millions\":\"GDP_USD_billions\"})\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_to_csv(df, csv_path):\n",
    "    ''' This function saves the final dataframe as a `CSV` file \n",
    "    in the provided path. Function returns nothing.'''\n",
    "    df.to_csv(csv_path)\n",
    "  \n",
    "\n",
    "\n",
    "def load_to_db(df, sql_connection, table_name):\n",
    "    ''' This function saves the final dataframe as a database table\n",
    "    with the provided name. Function returns nothing.'''\n",
    "    df.to_sql(table_name, sql_connection, if_exists = 'replace', index=False)\n",
    "    # print(\"Table is ready\")\n",
    "\n",
    "\n",
    "def run_query(query_statement, sql_connection):\n",
    "    ''' This function runs the stated query on the database table and\n",
    "    prints the output on the terminal. Function returns nothing. '''\n",
    "    print(query_statement)\n",
    "    query_output = pd.read_sql(query_statement, sql_connection)\n",
    "    print(query_output)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def log_progress(message):\n",
    "    ''' This function logs the mentioned message at a given stage of the code execution to a log file. Function returns nothing'''\n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second \n",
    "    now = datetime.now() # get current timestamp \n",
    "    timestamp = now.strftime(timestamp_format) \n",
    "    with open(log_file,\"a\") as f: \n",
    "        f.write(timestamp + ',' + message + '\\n') \n",
    "\n",
    "\n",
    "\n",
    "''' Here, you define the required entities and call the relevant \n",
    "functions in the correct order to complete the project. Note that this\n",
    "portion is not inside any function.'''\n",
    "\n",
    "\n",
    "log_progress('Preliminaries complete. Initiating ETL process')\n",
    "\n",
    "df = extract(url, table_attribs)\n",
    "\n",
    "log_progress('Data extraction complete. Initiating transformation process')\n",
    "\n",
    "df = transform(df)\n",
    "log_progress('Data transformation complete. Initiating loading process')\n",
    "\n",
    "load_to_csv(df, csv_path)\n",
    "\n",
    "log_progress('Data saved to CSV file')\n",
    "\n",
    "sql_connection = sqlite3.connect('World_Economies.db')\n",
    "\n",
    "log_progress('SQL Connection initiated')\n",
    "\n",
    "load_to_db(df, sql_connection, table_name)\n",
    "\n",
    "log_progress('Data loaded to Database as table. Running the query')\n",
    "\n",
    "query_statement = f\"SELECT * from {table_name} WHERE GDP_USD_billions >=100\"\n",
    "\n",
    "run_query(query_statement, sql_connection)\n",
    "\n",
    "log_progress(\"Process complete.\")\n",
    "\n",
    "sql_connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
